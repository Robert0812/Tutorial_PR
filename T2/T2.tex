\documentclass[compress,blue]{beamer}
\usepackage[latin1]{inputenc}
\usepackage{tikz}
\usepackage{mathtools}
\renewcommand\mathfamilydefault{\rmdefault}


\usetikzlibrary{shapes.arrows}
\tikzset{
    myarrow/.style={
        draw,
        fill=red,
        single arrow,
        minimum height=3.5ex,
        single arrow head extend=1ex
    }
}
\newcommand{\arrowup}{%
\tikz [baseline=-0.5ex]{\node [myarrow,rotate=90] {};}
}
\newcommand{\arrowdown}{%
\tikz [baseline=-1ex]{\node [myarrow,rotate=-90] {};}
}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bmu}{\mathbf{\mu}}
\newcommand{\bsig}{\mathbf{\sigma}}
\newcommand{\bSig}{\mathbf{\Sigma}}
\newcommand{\calD}{\mathcal{D}}

\usetheme{Warsaw}

\title[ENGG 5202 Pattern Recogntion Tutorial 2]{Tutorial 2: Maximum-Likelihood and \\ Bayesian Parameter Estimation}
\author{Rui Zhao}
\institute{rzhao@ee.cuhk.edu.hk}
\date{Jan. 23, 2014}

\begin{document}

\begin{frame}
\titlepage
\end{frame}

\setbeamertemplate{enumerate items}[square]
\setbeamertemplate{itemize items}[square]

\begin{frame}{Outline}
\setbeamercovered{transparent}
	\begin{enumerate}
		\item<1-> ML estimate: $\hat{\bSig}$ of multivariate Gaussian 
		\vspace{0.1in}
		\item<2-> ML estimate bias: $\hat{\sigma}^2$ of univariate Gaussian
		\vspace{0.1in}
		\item<3-> Bayesian estimate: Univariate Gaussian
		\begin{itemize}
			\item brief review
			\item posteriori $p(\mu|\calD)$
			\item conditional probability density $p(x | w_i, \calD_i)$
		\end{itemize}
	\end{enumerate}
\end{frame}

\begin{frame}{1. ML estimate: $\hat{\bSig}$ of multivariate Gaussian }
	\begin{block}{Multivariate Gassian Case: unknown $\bmu$ and $\bSig$}
		\begin{align}
			&\hat{\bmu} = \frac{1}{n}\sum_{k=1}^n\bx_k\\
			&\hat{\bSig} = \frac{1}{n}\sum_{k=1}^n(\bx_k - \hat{\bmu})(\bx_k - \hat{\bmu})^t
		\end{align}
		\small
		\begin{itemize}
			\item $\hat{\bmu}$ is the sample mean. 
			\item $\hat{\bSig}$ is the arithmetic average of the $n$ matrices $(\bx_k - \hat{\bmu})(\bx_k - \hat{\bmu})^t$.
		\end{itemize}
		\normalsize
	\end{block}	
\end{frame}

\begin{frame}{1. ML estimate: $\hat{\bSig}$ of multivariate Gaussian }
	\begin{block}{Multivariate normal density}
		\begin{align}
			p(\bx ~|~ \bmu,~ \bSig) = \frac{1}{(2\pi)^{d/2}|\bSig|^{1/2}} \exp\Big[-\frac{1}{2}(\bx-\bmu)^t\bSig^{-1}(\bx-\bmu)\Big]
		\end{align}
		\small
		Draw $\bx_1, \bx_2, \cdots, \bx_n$ independently from $p(\bx~|~\bmu,~\bSig)$, and the joint density (likelihood) is: 
		\begin{align}
			&p(\bx_1, \bx_2, \cdots, \bx_n~|~\bmu,\bSig) = \\
			&\qquad\frac{1}{(2\pi)^{nd/2}|\bSig|^{n/2}} \exp\Big[-\frac{1}{2}\sum_{k=1}^{n}(\bx_k-\bmu)^t\bSig^{-1}(\bx_k-\bmu)\Big]
		\end{align}
		Log-likelihood $l(\bmu, ~\bSig)$ is 
		\begin{align}
			&l(\bmu,\bSig) = -\frac{nd}{2}\ln(2\pi)-\frac{n}{2}\ln|\bSig| -\frac{1}{2}\sum_{k=1}^{n}(\bx_k-\bmu)^t\bSig^{-1}(\bx_k-\bmu)
		\end{align}
		\normalsize
	\end{block}
\end{frame}

\begin{frame}{1. ML estimate: $\hat{\bSig}$ of multivariate Gaussian }
	\begin{block}{Multivariate normal density}
		\small
		Let $A = \bSig^{-1}$
		\begin{align}
			&l(\bmu,\bSig) = -\frac{nd}{2}\ln(2\pi)-\frac{n}{2}\ln|\bSig| -\frac{1}{2}\sum_{k=1}^{n}(\bx_k-\bmu)^t\bSig^{-1}(\bx_k-\bmu) \\ 
			&l(\bmu,\bSig) = -\frac{nd}{2}\ln(2\pi)+\frac{n}{2}\ln \mathbf{A} -\frac{1}{2}\sum_{k=1}^{n}(\bx_k-\bmu)^t \mathbf{A}(\bx_k-\bmu)\\
			& \frac{\partial l(\bmu,\bSig)}{\partial \mathbf{A} } = \frac{n}{2} \mathbf{A}^{-1} - \frac{1}{2} \sum_{k=1}^{n} (\bx_k-\bmu)(\bx_k-\bmu)^t = 0
		\end{align}
		Replace $\mathbf{A}$ by $\bSig^{-1}$ 
		\begin{align}
			\hat{\bSig} = \frac{1}{n} \sum_{k=1}^n (\bx_k-\hat{\bmu})(\bx_k-\hat{\bmu})^t, ~~ (\hat{\bmu} = \frac{1}{n}\sum_{k=1}^n \bx_k)
		\end{align}
		\normalsize
	\end{block}
\end{frame}

\begin{frame}{Outline}
\setbeamercovered{transparent}
	\begin{enumerate}
		\item<1-> ML estimate: $\hat{\bSig}$ of multivariate Gaussian 
		\vspace{0.1in}
		\item<2-> ML estimate bias: $\hat{\sigma}^2$ of univariate Gaussian
		\vspace{0.1in}
		\item<0> Bayesian estimate: Univariate Gaussian
		\begin{itemize}
			\item brief review
			\item posteriori $p(\mu|\calD)$
			\item conditional probability density $p(x | w_i, \calD_i)$
		\end{itemize}
	\end{enumerate}
\end{frame}

\begin{frame}{ML estimate bias: $\hat{\sigma}^2$ of univariate Gaussian}
	\begin{block}{Univariate Gassian Case}
		ML estimator $\hat{\sigma}^2$ is biased.
		\begin{align}
			E[\hat{\sigma}^2] = E[\frac{1}{n}\sum_{k=1}^{n}(x_k-\hat{\mu})^2] = \frac{n-1}{n}\sigma^2
		\end{align}
		\small
		An elementary unbiased estimator for $\sigma^2$ is given by $\frac{1}{n-1}\sum_{k=1}^n(x_k - \hat{\mu})$.
		\normalsize
	\end{block}	
\end{frame}

\begin{frame}{ML estimate bias: $\hat{\sigma}^2$ of univariate Gaussian}
	\begin{block}{Univariate Gassian Case}
		\vspace{-0.15in}
		\tiny
		\begin{align}
			E[\frac{1}{n}\sum_{k=1}^{n}(x_k-\hat{\mu})^2] &= E\Big[\frac{1}{n}\sum_{k=1}^{n}(x_k-\frac{1}{n}\sum_{j=1}^n x_j)^2\Big]\\
			&=E\Big[\frac{1}{n}\sum_{k=1}^{n}\big(x^2_k -\frac{2}{n}x_k\sum_{j=1}^n x_j + \frac{1}{n^2}(\sum_{j=1}^n x_j)^2\big)\Big]\\
			&=E\Big[\frac{1}{n}\Big(\sum_{k=1}^{n} x^2_k -\frac{2}{n}(\sum_{k=1}^n x_k)^2 + \frac{n}{n^2}(\sum_{k=1}^n x_k)^2\Big)\Big]\\
			&=E\Big[\frac{1}{n}\Big(\sum_{k=1}^{n} x^2_k -\frac{1}{n}(\sum_{k=1}^n x_k)^2 \Big)\Big] \\
			&=\frac{1}{n}E[\sum_{k=1}^{n} x^2_k] - \frac{1}{n^2}E[(\sum_{k=1}^n x_k)^2]\\
			&=E[x^2] - \frac{1}{n^2}E\Big[\sum_{k=1}^n x_k^2 + \sum_{i\neq j}x_i x_j\Big] \\
			&= E[x^2] - \frac{1}{n^2}E[\sum_{k=1}^n x_k^2] - \frac{1}{n^2}E[\sum_{i\neq j}x_i x_j] \\
			&= E[x^2] -\frac{1}{n} E[x^2] - \frac{n^2-n}{n^2}E[x_i x_j] = \frac{n-1}{n}\Big(E[x^2] - (E[x])^2\Big)\\
			& = \frac{n-1}{n} \sigma^2
		\end{align}
		\normalsize
	\end{block}
\end{frame}

\begin{frame}{Outline}
\setbeamercovered{transparent}
	\begin{enumerate}
		\item<1-> ML estimate: $\hat{\bSig}$ of multivariate Gaussian 
		\vspace{0.1in}
		\item<1-> ML estimate bias: $\hat{\sigma}^2$ of univariate Gaussian
		\vspace{0.1in}
		\item<2-> Bayesian estimate: Univariate Gaussian
		\begin{itemize}
			\item<3-> brief review
			\item<0> posteriori $p(\mu|\calD)$
			\item<0> conditional probability density $p(x | w_i, \calD_i)$
		\end{itemize}
	\end{enumerate}
\end{frame}

\end{document} 